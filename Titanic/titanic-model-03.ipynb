{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54ad7202",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-03T15:26:21.916660Z",
     "iopub.status.busy": "2025-12-03T15:26:21.916240Z",
     "iopub.status.idle": "2025-12-03T15:26:29.978109Z",
     "shell.execute_reply": "2025-12-03T15:26:29.976845Z"
    },
    "papermill": {
     "duration": 8.069402,
     "end_time": "2025-12-03T15:26:29.979703",
     "exception": false,
     "start_time": "2025-12-03T15:26:21.910301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "/kaggle/input/titanic/train.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/gender_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6125973b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T15:26:29.988507Z",
     "iopub.status.busy": "2025-12-03T15:26:29.987986Z",
     "iopub.status.idle": "2025-12-03T15:26:30.038492Z",
     "shell.execute_reply": "2025-12-03T15:26:30.037318Z"
    },
    "papermill": {
     "duration": 0.056737,
     "end_time": "2025-12-03T15:26:30.040158",
     "exception": false,
     "start_time": "2025-12-03T15:26:29.983421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "717ac71c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T15:26:30.049249Z",
     "iopub.status.busy": "2025-12-03T15:26:30.048895Z",
     "iopub.status.idle": "2025-12-03T15:26:30.069358Z",
     "shell.execute_reply": "2025-12-03T15:26:30.068293Z"
    },
    "papermill": {
     "duration": 0.02707,
     "end_time": "2025-12-03T15:26:30.071122",
     "exception": false,
     "start_time": "2025-12-03T15:26:30.044052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e439b0fa",
   "metadata": {
    "papermill": {
     "duration": 0.003731,
     "end_time": "2025-12-03T15:26:30.078919",
     "exception": false,
     "start_time": "2025-12-03T15:26:30.075188",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Processing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45af9b91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T15:26:30.088094Z",
     "iopub.status.busy": "2025-12-03T15:26:30.087708Z",
     "iopub.status.idle": "2025-12-03T15:26:30.124897Z",
     "shell.execute_reply": "2025-12-03T15:26:30.123779Z"
    },
    "papermill": {
     "duration": 0.044087,
     "end_time": "2025-12-03T15:26:30.126634",
     "exception": false,
     "start_time": "2025-12-03T15:26:30.082547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape: (891, 12)\n",
      "Test features shape : (418, 12)\n"
     ]
    }
   ],
   "source": [
    "# Combine for consistent feature engineering\n",
    "full = pd.concat([train_data, test_data], sort=False).reset_index(drop=True)\n",
    "\n",
    "# Fill missing values\n",
    "full[\"Age\"] = full[\"Age\"].fillna(full[\"Age\"].median())\n",
    "full[\"Fare\"] = full[\"Fare\"].fillna(full[\"Fare\"].median())\n",
    "full[\"Embarked\"] = full[\"Embarked\"].fillna(full[\"Embarked\"].mode()[0])\n",
    "\n",
    "# Family size & being alone (same as your model2)\n",
    "full[\"FamilySize\"] = full[\"SibSp\"] + full[\"Parch\"] + 1\n",
    "full[\"IsAlone\"] = (full[\"FamilySize\"] == 1).astype(int)\n",
    "\n",
    "# Feature list\n",
    "features = [\n",
    "    \"Pclass\",\n",
    "    \"Sex\",\n",
    "    \"Age\",\n",
    "    \"Fare\",\n",
    "    \"Embarked\",\n",
    "    \"SibSp\",\n",
    "    \"Parch\",\n",
    "    \"FamilySize\",\n",
    "    \"IsAlone\",\n",
    "]\n",
    "\n",
    "# Split back into train / test\n",
    "full_train = full.iloc[:len(train_data)]\n",
    "full_test  = full.iloc[len(train_data):]\n",
    "\n",
    "X = full_train[features]\n",
    "X_test = full_test[features]\n",
    "y = train_data[\"Survived\"]\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X = pd.get_dummies(X)\n",
    "X_test = pd.get_dummies(X_test)\n",
    "\n",
    "# Align columns between train and test\n",
    "X, X_test = X.align(X_test, join=\"left\", axis=1)\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "print(\"Train features shape:\", X.shape)\n",
    "print(\"Test features shape :\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59578bf8",
   "metadata": {
    "papermill": {
     "duration": 0.003704,
     "end_time": "2025-12-03T15:26:30.135392",
     "exception": false,
     "start_time": "2025-12-03T15:26:30.131688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "936207d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T15:26:30.147552Z",
     "iopub.status.busy": "2025-12-03T15:26:30.147208Z",
     "iopub.status.idle": "2025-12-03T15:26:30.175023Z",
     "shell.execute_reply": "2025-12-03T15:26:30.172860Z"
    },
    "papermill": {
     "duration": 0.036748,
     "end_time": "2025-12-03T15:26:30.177667",
     "exception": false,
     "start_time": "2025-12-03T15:26:30.140919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b666574",
   "metadata": {
    "papermill": {
     "duration": 0.005865,
     "end_time": "2025-12-03T15:26:30.191069",
     "exception": false,
     "start_time": "2025-12-03T15:26:30.185204",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Split for Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4e2f2a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T15:26:30.205955Z",
     "iopub.status.busy": "2025-12-03T15:26:30.205416Z",
     "iopub.status.idle": "2025-12-03T15:26:30.216483Z",
     "shell.execute_reply": "2025-12-03T15:26:30.215454Z"
    },
    "papermill": {
     "duration": 0.020627,
     "end_time": "2025-12-03T15:26:30.218702",
     "exception": false,
     "start_time": "2025-12-03T15:26:30.198075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (712, 12)\n",
      "Val size  : (179, 12)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_scaled, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape)\n",
    "print(\"Val size  :\", X_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5dc69c",
   "metadata": {
    "papermill": {
     "duration": 0.006204,
     "end_time": "2025-12-03T15:26:30.233388",
     "exception": false,
     "start_time": "2025-12-03T15:26:30.227184",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## PyTorch Tensors & DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "198e61af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T15:26:30.244395Z",
     "iopub.status.busy": "2025-12-03T15:26:30.243726Z",
     "iopub.status.idle": "2025-12-03T15:26:30.289119Z",
     "shell.execute_reply": "2025-12-03T15:26:30.288280Z"
    },
    "papermill": {
     "duration": 0.052324,
     "end_time": "2025-12-03T15:26:30.290976",
     "exception": false,
     "start_time": "2025-12-03T15:26:30.238652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Datasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset   = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "# DataLoaders\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245f4c10",
   "metadata": {
    "papermill": {
     "duration": 0.003784,
     "end_time": "2025-12-03T15:26:30.298851",
     "exception": false,
     "start_time": "2025-12-03T15:26:30.295067",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1c14e4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T15:26:30.307683Z",
     "iopub.status.busy": "2025-12-03T15:26:30.307332Z",
     "iopub.status.idle": "2025-12-03T15:26:30.339848Z",
     "shell.execute_reply": "2025-12-03T15:26:30.338666Z"
    },
    "papermill": {
     "duration": 0.038942,
     "end_time": "2025-12-03T15:26:30.341464",
     "exception": false,
     "start_time": "2025-12-03T15:26:30.302522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TitanicNet(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=12, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.3, inplace=False)\n",
      "    (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): Linear(in_features=16, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class TitanicNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(TitanicNet, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(16, 1)  # output logits for BCEWithLogitsLoss\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "model = TitanicNet(input_dim).to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7d9e6f",
   "metadata": {
    "papermill": {
     "duration": 0.003861,
     "end_time": "2025-12-03T15:26:30.349512",
     "exception": false,
     "start_time": "2025-12-03T15:26:30.345651",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Set Up Loss Function, Optimizer, and Training Loop with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a9d235b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T15:26:30.359511Z",
     "iopub.status.busy": "2025-12-03T15:26:30.358468Z",
     "iopub.status.idle": "2025-12-03T15:26:37.851370Z",
     "shell.execute_reply": "2025-12-03T15:26:37.850036Z"
    },
    "papermill": {
     "duration": 7.499729,
     "end_time": "2025-12-03T15:26:37.853144",
     "exception": false,
     "start_time": "2025-12-03T15:26:30.353415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 0.6534 | Val Loss: 0.6358 | Val Acc: 0.7709\n",
      "Epoch 002 | Train Loss: 0.5789 | Val Loss: 0.5409 | Val Acc: 0.7765\n",
      "Epoch 003 | Train Loss: 0.5061 | Val Loss: 0.4877 | Val Acc: 0.8101\n",
      "Epoch 004 | Train Loss: 0.4724 | Val Loss: 0.4645 | Val Acc: 0.7989\n",
      "Epoch 005 | Train Loss: 0.4474 | Val Loss: 0.4546 | Val Acc: 0.8212\n",
      "Epoch 006 | Train Loss: 0.4354 | Val Loss: 0.4505 | Val Acc: 0.8101\n",
      "Epoch 007 | Train Loss: 0.4372 | Val Loss: 0.4422 | Val Acc: 0.8101\n",
      "Epoch 008 | Train Loss: 0.4504 | Val Loss: 0.4371 | Val Acc: 0.8156\n",
      "Epoch 009 | Train Loss: 0.4295 | Val Loss: 0.4392 | Val Acc: 0.8268\n",
      "Epoch 010 | Train Loss: 0.4434 | Val Loss: 0.4441 | Val Acc: 0.8212\n",
      "Epoch 011 | Train Loss: 0.4103 | Val Loss: 0.4425 | Val Acc: 0.8212\n",
      "Epoch 012 | Train Loss: 0.4152 | Val Loss: 0.4446 | Val Acc: 0.8268\n",
      "Epoch 013 | Train Loss: 0.4354 | Val Loss: 0.4477 | Val Acc: 0.8324\n",
      "Epoch 014 | Train Loss: 0.4165 | Val Loss: 0.4401 | Val Acc: 0.8324\n",
      "Epoch 015 | Train Loss: 0.4138 | Val Loss: 0.4435 | Val Acc: 0.8268\n",
      "Epoch 016 | Train Loss: 0.4195 | Val Loss: 0.4455 | Val Acc: 0.8268\n",
      "Epoch 017 | Train Loss: 0.4399 | Val Loss: 0.4486 | Val Acc: 0.8212\n",
      "Epoch 018 | Train Loss: 0.3962 | Val Loss: 0.4460 | Val Acc: 0.8212\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 100\n",
    "patience = 10  # early stopping patience\n",
    "\n",
    "best_val_loss = np.inf\n",
    "epochs_no_improve = 0\n",
    "best_state_dict = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # ========= Train =========\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    avg_train_loss = np.mean(train_losses)\n",
    "\n",
    "    # ========= Validate =========\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    y_val_true = []\n",
    "    y_val_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            logits = model(X_batch)\n",
    "            loss = criterion(logits, y_batch)\n",
    "            val_losses.append(loss.item())\n",
    "\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs > 0.5).float()\n",
    "\n",
    "            y_val_true.extend(y_batch.cpu().numpy())\n",
    "            y_val_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    val_acc = accuracy_score(y_val_true, y_val_pred)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1:03d} | \"\n",
    "        f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "        f\"Val Loss: {avg_val_loss:.4f} | \"\n",
    "        f\"Val Acc: {val_acc:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Early stopping check\n",
    "    if avg_val_loss < best_val_loss - 1e-4:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_no_improve = 0\n",
    "        best_state_dict = model.state_dict()\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# Load best weights\n",
    "if best_state_dict is not None:\n",
    "    model.load_state_dict(best_state_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edcf817",
   "metadata": {
    "papermill": {
     "duration": 0.005292,
     "end_time": "2025-12-03T15:26:37.864111",
     "exception": false,
     "start_time": "2025-12-03T15:26:37.858819",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Retrain on Full Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "831bae52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T15:26:37.874213Z",
     "iopub.status.busy": "2025-12-03T15:26:37.873740Z",
     "iopub.status.idle": "2025-12-03T15:26:41.042560Z",
     "shell.execute_reply": "2025-12-03T15:26:41.041383Z"
    },
    "papermill": {
     "duration": 3.176093,
     "end_time": "2025-12-03T15:26:41.044315",
     "exception": false,
     "start_time": "2025-12-03T15:26:37.868222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Epoch 001 | Loss: 0.6406\n",
      "Final Train Epoch 002 | Loss: 0.5517\n",
      "Final Train Epoch 003 | Loss: 0.5033\n",
      "Final Train Epoch 004 | Loss: 0.4836\n",
      "Final Train Epoch 005 | Loss: 0.4503\n",
      "Final Train Epoch 006 | Loss: 0.4522\n",
      "Final Train Epoch 007 | Loss: 0.4366\n",
      "Final Train Epoch 008 | Loss: 0.4359\n",
      "Final Train Epoch 009 | Loss: 0.4251\n",
      "Final Train Epoch 010 | Loss: 0.4356\n",
      "Final Train Epoch 011 | Loss: 0.4293\n",
      "Final Train Epoch 012 | Loss: 0.4135\n",
      "Final Train Epoch 013 | Loss: 0.4187\n",
      "Final Train Epoch 014 | Loss: 0.3946\n",
      "Final Train Epoch 015 | Loss: 0.4096\n",
      "Final Train Epoch 016 | Loss: 0.3910\n",
      "Final Train Epoch 017 | Loss: 0.4166\n",
      "Final Train Epoch 018 | Loss: 0.4203\n",
      "Final Train Epoch 019 | Loss: 0.4188\n",
      "Final Train Epoch 020 | Loss: 0.4098\n",
      "Final Train Epoch 021 | Loss: 0.4125\n",
      "Final Train Epoch 022 | Loss: 0.4196\n",
      "Final Train Epoch 023 | Loss: 0.4079\n",
      "Final Train Epoch 024 | Loss: 0.4146\n",
      "Final Train Epoch 025 | Loss: 0.4106\n",
      "Final Train Epoch 026 | Loss: 0.4023\n",
      "Final Train Epoch 027 | Loss: 0.3967\n",
      "Final Train Epoch 028 | Loss: 0.4128\n",
      "Final Train Epoch 029 | Loss: 0.4077\n",
      "Final Train Epoch 030 | Loss: 0.4080\n",
      "Final Train Epoch 031 | Loss: 0.3914\n",
      "Final Train Epoch 032 | Loss: 0.3975\n",
      "Final Train Epoch 033 | Loss: 0.4040\n",
      "Final Train Epoch 034 | Loss: 0.3962\n",
      "Final Train Epoch 035 | Loss: 0.4116\n",
      "Final Train Epoch 036 | Loss: 0.4011\n",
      "Final Train Epoch 037 | Loss: 0.3909\n",
      "Final Train Epoch 038 | Loss: 0.3886\n",
      "Final Train Epoch 039 | Loss: 0.4062\n",
      "Final Train Epoch 040 | Loss: 0.3934\n"
     ]
    }
   ],
   "source": [
    "# Full training data tensors\n",
    "X_full_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y_full_tensor = torch.tensor(y.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "full_dataset = TensorDataset(X_full_tensor, y_full_tensor)\n",
    "full_loader  = DataLoader(full_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "final_model = TitanicNet(input_dim).to(device)\n",
    "final_criterion = nn.BCEWithLogitsLoss()\n",
    "final_optimizer = torch.optim.Adam(final_model.parameters(), lr=1e-3)\n",
    "\n",
    "final_epochs = 40  # e.g. fixed number\n",
    "\n",
    "for epoch in range(final_epochs):\n",
    "    final_model.train()\n",
    "    train_losses = []\n",
    "    for X_batch, y_batch in full_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        final_optimizer.zero_grad()\n",
    "        logits = final_model(X_batch)\n",
    "        loss = final_criterion(logits, y_batch)\n",
    "        loss.backward()\n",
    "        final_optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    print(f\"Final Train Epoch {epoch+1:03d} | Loss: {np.mean(train_losses):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd40eaa4",
   "metadata": {
    "papermill": {
     "duration": 0.006431,
     "end_time": "2025-12-03T15:26:41.056970",
     "exception": false,
     "start_time": "2025-12-03T15:26:41.050539",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Make Prediction and Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89e4fd64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T15:26:41.068133Z",
     "iopub.status.busy": "2025-12-03T15:26:41.067825Z",
     "iopub.status.idle": "2025-12-03T15:26:41.085102Z",
     "shell.execute_reply": "2025-12-03T15:26:41.083867Z"
    },
    "papermill": {
     "duration": 0.025112,
     "end_time": "2025-12-03T15:26:41.086922",
     "exception": false,
     "start_time": "2025-12-03T15:26:41.061810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file 'submission_pytorch_dl.csv' was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
    "\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits_test = final_model(X_test_tensor)\n",
    "    probs_test = torch.sigmoid(logits_test)\n",
    "    preds_test = (probs_test > 0.5).float().cpu().numpy().ravel()\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": test_data[\"PassengerId\"],\n",
    "    \"Survived\": preds_test.astype(int)\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission_pytorch_dl.csv\", index=False)\n",
    "print(\"Submission file 'submission_pytorch_dl.csv' was successfully saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27.232527,
   "end_time": "2025-12-03T15:26:44.262763",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-03T15:26:17.030236",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
